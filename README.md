# Cross_Val-vs-Train_Test

ğŸš€ Train-Test Split vs Cross-Validation â€” When and Why? ğŸ¤”

In machine learning, choosing the right evaluation strategy can make or break your model's performance. Hereâ€™s a quick guide I explored in the notebook:
ğŸ” Train-Test Split
âœ… Simple & fast (e.g., 80/20 or 70/30 split)
âœ… Ideal for large datasets
âŒ High variance on small or unbalanced data

ğŸ“Œ Use when:
â€¢ You need a quick performance check
â€¢ Your dataset is huge
â€¢ You're doing final evaluation before deployment

ğŸ” Cross-Validation (e.g., K-Fold)
âœ… More robust and reliable
âœ… Reduces variance by averaging multiple train/test combinations
âŒ Takes more time/computation

ğŸ“Œ Use when:
â€¢ Dataset is small to medium
â€¢ You're comparing models
â€¢ You're tuning hyperparameters
â€¢ You want a stable and fair performance estimate

ğŸ’¡ In my GitHub notebook, I walk through real Python code using scikit-learn, showing how different strategies can influence your results â€” and how to avoid data leakage when applying scaling or encoding.

ğŸ¯ Purpose of the Notebook
To compare model performance using:
1. Train-Test Split
2. Cross-Validation

ğŸ“¦ Step-by-Step Code Summary
âœ… 1. Imports & Dataset
âœ… 2. EDA & Plotting
âœ… 3. Train-Test Split Evaluation
 Result of using Train-Test Split
 
    ğŸ† Model Evaluation Complete ğŸ† 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Model                  â”‚   Accuracy â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ XGBClassifier          â”‚       0.84 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LogisticRegression     â”‚       0.82 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ RandomForestClassifier â”‚       0.82 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ KNeighborsClassifier   â”‚       0.7  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ SVC                    â”‚       0.69 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•›

âœ… 4. Cross-Validation
 Result of using Train-Test Split

    ğŸ† Model Evaluation Complete ğŸ† 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â••
â”‚ Model                  â”‚   Accuracy â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ RandomForestClassifier â”‚       0.84 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LogisticRegression     â”‚       0.83 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ SVC                    â”‚       0.83 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ XGBClassifier          â”‚       0.79 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ KNeighborsClassifier   â”‚       0.64 â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•›

ğŸ§  Final Thought:
Using both methods together is a great way to:
â€¢ Compare evaluation strategies
â€¢ Avoid overfitting
â€¢ Choose the most trustworthy model
